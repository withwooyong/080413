import streamlit as st
from dotenv import load_dotenv
from langchain_community.chat_models import ChatOpenAI

st.set_page_config(page_title="ğŸ¦œğŸ”— ë­ë“ ì§€ ì§ˆë¬¸í•˜ì„¸ìš”~ ")
st.title('ğŸ¦œğŸ”— ë­ë“ ì§€ ì§ˆë¬¸í•˜ì„¸ìš”~ ')

load_dotenv()


# os.environ["OPENAI_API_KEY"] = "sk-"  # openai í‚¤ ì…ë ¥

def generate_response(input_text):  # llmì´ ë‹µë³€ ìƒì„±
    # # ì°½ì˜ì„± 0ìœ¼ë¡œ ì„¤ì •, # ëª¨ë¸ëª…
    llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')
    st.info(llm.predict(input_text))


with st.form('Question'):
    text = st.text_area('ì§ˆë¬¸ ì…ë ¥:', 'What types of text models does OpenAI provide?')  # ì²« í˜ì´ì§€ê°€ ì‹¤í–‰ë  ë•Œ ë³´ì—¬ì¤„ ì§ˆë¬¸
    submitted = st.form_submit_button('ë³´ë‚´ê¸°')
    generate_response(text)

# streamlit run 5_1_chatbot.py
