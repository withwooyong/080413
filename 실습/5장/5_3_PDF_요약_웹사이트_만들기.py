#!/usr/bin/env python
# coding: utf-8

# In[1]:


#!pip install langchain


# In[2]:


#!pip install streamlit


# In[3]:


#!pip install PyPDF2


# In[4]:


#!pip install sentence-transformers


# In[5]:


import os
from PyPDF2 import PdfReader
import streamlit as st
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.chat_models import ChatOpenAI
from langchain.callbacks import get_openai_callback

def process_text(text): 
#CharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)

    #ì„ë² ë”© ì²˜ë¦¬(ë²¡í„° ë³€í™˜), ì„ë² ë”©ì€ HuggingFaceEmbeddings ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')
    documents = FAISS.from_texts(chunks, embeddings)
    return documents

def main():  #streamlitì„ ì´ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ìƒì„±
    st.title("ğŸ“„PDF ìš”ì•½í•˜ê¸°")
    st.divider()
    try:
        os.environ["OPENAI_API_KEY"] = "sk-" #openai api í‚¤ ì…ë ¥
    except ValueError as e:
        st.error(str(e))
        return

    pdf = st.file_uploader('PDFíŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”', type='pdf')

    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text = ""   # í…ìŠ¤íŠ¸ ë³€ìˆ˜ì— PDF ë‚´ìš©ì„ ì €ì¥
        for page in pdf_reader.pages:
            text += page.extract_text()

        documents = process_text(text)
        query = "ì—…ë¡œë“œëœ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ì•½ 3~5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."  # LLMì— PDFíŒŒì¼ ìš”ì•½ ìš”ì²­

        if query:
            docs = documents.similarity_search(query)
            llm = ChatOpenAI(model="gpt-3.5-turbo-16k", temperature=0.1)
            chain = load_qa_chain(llm, chain_type='stuff')

            with get_openai_callback() as cost:
                response = chain.run(input_documents=docs, question=query)
                print(cost)

            st.subheader('--ìš”ì•½ ê²°ê³¼--:')
            st.write(response)

if __name__ == '__main__':
    main()


# In[ ]:




